# jarvis_voice.py
# Enhanced for basic conversational interaction with STT and modified TTS.

# Installation:
# 1. Make sure you have Python installed.
# 2. Install necessary Python packages by opening a terminal or command prompt and running:
#    pip install kokoro soundfile torch SpeechRecognition PyAudio numpy playsound==1.2.2 ollama
# 3. Kokoro TTS relies on espeak-ng. You will need to install it separately.
#    - For Windows: Download and install from the espeak-ng GitHub releases page
#      (https://github.com/espeak-ng/espeak-ng/releases) or try installing via a package
#      manager like Chocolatey if available (`choco install espeak-ng`).
#      Ensure the installation directory is added to your system's PATH.
#    - For Debian/Ubuntu: sudo apt-get install espeak-ng
#    - For macOS: brew install espeak-ng
# 4. PyAudio might require additional steps if `pip install PyAudio` fails.
#    On Windows, you might need to install from a precompiled wheel or use pipwin.
#    On Linux, you might need `portaudio19-dev` (e.g., `sudo apt-get install portaudio19-dev`).
# 5. This script now uses Ollama for response generation.
#    - Install Ollama from https://ollama.com/
#    - Pull the Llama 3.2 model: `ollama pull llama3.2` (or your preferred model)
#    - Ensure Ollama is running when you execute this script.

import os
from datetime import datetime
try:
    from kokoro import KPipeline
    import soundfile as sf
    import torch
    import speech_recognition as sr
    import numpy as np
    from playsound import playsound
    import ollama
except ImportError as e:
    print(f"Error importing libraries: {e}")
    print("Please ensure you have run: pip install kokoro soundfile torch SpeechRecognition PyAudio numpy playsound==1.2.2 ollama")
    print("And that all dependencies, including espeak-ng and PyAudio's dependencies, are correctly installed.")
    exit(1)

# Global Kokoro pipeline instance to avoid re-initializing every time
KOKORO_PIPELINE = None

def initialize_kokoro():
    global KOKORO_PIPELINE
    if KOKORO_PIPELINE is None:
        print("Initializing Kokoro TTS pipeline...")
        try:
            # lang_code='a' and voice='af_heart' are from the example.
            # Refer to Kokoro documentation or VOICES.md for more language and voice options.
            KOKORO_PIPELINE = KPipeline(lang_code='a')
            print("Kokoro TTS pipeline initialized successfully.")
        except Exception as e:
            print(f"Fatal Error initializing KPipeline: {e}")
            print("This might be due to missing dependencies like espeak-ng.")
            print("Please ensure espeak-ng is installed and its installation directory is in your system's PATH.")
            KOKORO_PIPELINE = "error" # Mark as error to prevent retries
    return KOKORO_PIPELINE != "error"

def generate_speech(text_to_speak, base_filename="jarvis_response"):
    """
    Generates speech from text using Kokoro TTS and saves it to a uniquely named WAV file.
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    output_filename = f"{base_filename}_{timestamp}.wav"
    if KOKORO_PIPELINE is None or KOKORO_PIPELINE == "error":
        if not initialize_kokoro():
            print("Cannot generate speech due to Kokoro initialization failure.")
            return None

    if not text_to_speak or not text_to_speak.strip():
        print("JARVIS: Text to speak is empty. Cannot generate speech.")
        return None

    print(f"JARVIS generating speech for (full text): \"{text_to_speak}\"")
    
    try:
        generator = KOKORO_PIPELINE(text_to_speak, voice='af_heart')
        
        all_audio_chunks = []
        for i, (gs, ps, audio_chunk) in enumerate(generator):
            # print(f"Processing chunk {i} (gs: {gs}, ps: {ps})") # Optional: for detailed logging
            all_audio_chunks.append(audio_chunk)
            
        if not all_audio_chunks:
            print("No audio was generated by Kokoro. Check the input text and model compatibility.")
            return None
        
        # Concatenate all audio chunks
        full_audio = np.concatenate(all_audio_chunks)
        
        # Ensure the output directory exists (though for a single file, current dir is fine)
        # os.makedirs(os.path.dirname(output_filename), exist_ok=True) # If saving to a sub-directory
        
        sf.write(output_filename, full_audio, 24000) # Kokoro example uses 24000 Hz sample rate
        print(f"JARVIS speech saved to {output_filename}")
        return output_filename
            
    except Exception as e:
        print(f"Error during speech generation: {e}")
        return None

def listen_for_command():
    """
    Listens for a command from the user via microphone and returns the recognized text.
    """
    recognizer = sr.Recognizer()
    microphone = sr.Microphone()

    with microphone as source:
        print("\nCalibrating microphone for ambient noise...")
        recognizer.adjust_for_ambient_noise(source, duration=1)
        print("JARVIS is listening... (Say 'exit' or 'quit' to stop)")
        try:
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=10)
        except sr.WaitTimeoutError:
            print("JARVIS: No speech detected within the time limit.")
            return None

    try:
        print("JARVIS processing your speech...")
        command = recognizer.recognize_google(audio)
        print(f"You said: {command}")
        return command.lower()
    except sr.UnknownValueError:
        print("JARVIS: Sorry, I could not understand what you said.")
        return None
    except sr.RequestError as e:
        print(f"JARVIS: Could not request results from Google Speech Recognition service; {e}")
        print("         Please check your internet connection.")
        return None
    except Exception as e:
        print(f"JARVIS: An unexpected error occurred during speech recognition: {e}")
        return None

def get_jarvis_response(user_input):
    """
    Generates a conversational response based on user input using Ollama.
    """
    if not user_input:
        return "I didn't catch that. Could you please repeat?"

    print(f"JARVIS sending to Ollama (llama3.2): \"{user_input[:50]}...\"")
    try:
        # Ensure Ollama server is running and llama3.2 model is pulled.
        response = ollama.chat(
            model='llama3.2', # Or your preferred model if different
            messages=[
                {
                    'role': 'system',
                    'content': 'You are JARVIS, a helpful and friendly AI assistant. Respond conversationally and aim to be concise. If the user asks a question you cannot answer, politely say so. Do not return empty responses.'
                },
                {
                    'role': 'user',
                    'content': user_input,
                }
            ]
        )
        llm_response = response['message']['content'].strip()
        if not llm_response:
            print("JARVIS: Ollama returned an empty response.")
            return "I'm not sure how to respond to that. Could you try asking differently?"
        return llm_response
    except ollama.ResponseError as e:
        print(f"JARVIS: Error communicating with Ollama: {e.error}")
        if "model not found" in e.error.lower():
            return "I'm having trouble accessing my language model. Please ensure 'llama3.2' is pulled in Ollama."
        return "I'm sorry, I'm having trouble thinking of a response right now. Please check if Ollama is running."
    except Exception as e:
        print(f"JARVIS: An unexpected error occurred while getting LLM response: {e}")
        return "An unexpected error occurred while trying to generate a response."

if __name__ == "__main__":
    if not initialize_kokoro():
        print("Exiting script as Kokoro TTS could not be initialized.")
        exit(1)

    print("\n--- JARVIS Interactive Mode Activated ---")
    print("Speak your command after 'JARVIS is listening...' prompt.")
    print("Say 'exit' or 'quit' to end the session.")

    while True:
        user_input = listen_for_command()

        if user_input:
            if user_input in ["exit", "quit", "stop", "goodbye"]:
                farewell_message = "Goodbye! Shutting down."
                print(f"JARVIS: {farewell_message}")
                farewell_audio_file = generate_speech(farewell_message, "jarvis_farewell")
                if farewell_audio_file:
                    try:
                        print(f"JARVIS playing farewell message...")
                        playsound(farewell_audio_file)
                    except Exception as e:
                        print(f"Error playing farewell sound: {e}")
                break
            
            response_text = get_jarvis_response(user_input)
            print(f"JARVIS responding: {response_text}") # Log the text response

            output_audio_file = generate_speech(response_text)
            if output_audio_file:
                print(f"JARVIS response audio is ready at: {os.path.abspath(output_audio_file)}")
                print("You can play it using your system's default audio player.")
                # To play automatically, you might use a library like 'playsound' or 'simpleaudio'
                try:
                    print(f"JARVIS playing response...")
                    playsound(output_audio_file)
                except Exception as e:
                    print(f"Error playing sound: {e}. Ensure you have a media player backend for playsound (e.g., on Windows, playsound often uses the default media player; on Linux, you might need GStreamer or other libraries).")
            else:
                print("JARVIS: Failed to generate speech response.")
        else:
            # If listen_for_command returned None (e.g., timeout, error)
            print("JARVIS: Waiting for your next command.")
        
        print("-" * 20) # Separator for clarity

    print("\nJARVIS session ended.")
    print(f"You can find generated .wav files in the current directory: {os.getcwd()}")